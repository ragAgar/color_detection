{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#訓練データの正解データ\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "basepath = \"../first_retailing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv(basepath+\"train_master.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utils\n",
    "#画像のpixelを作成\n",
    "def get_img_array(path,resize):\n",
    "    img_array = Image.open(path).resize([resize,resize]).getdata()\n",
    "    return img_array\n",
    "\n",
    "#画像を表示\n",
    "def show_img(path):\n",
    "    img_array = Image.open(path).resize([128,128])\n",
    "    img_array.show()\n",
    "\n",
    "#精度\n",
    "def M_accuracy(true, pred):\n",
    "    M_acc = {}\n",
    "    for i in range(24):\n",
    "        y_id = pred[true[\"category_id\"].values==i] == i\n",
    "        M_acc[i]=np.mean(y_id)\n",
    "    return  np.mean([j for j in M_acc.values()])\n",
    "\n",
    "\n",
    "#pickle書き出し(<4GB)\n",
    "import pickle\n",
    "def write_pickle(pickle_path,v):\n",
    "    with open(pickle_path, mode='wb') as f:\n",
    "        pickle.dump(v, f)\n",
    "    print(\"Finished Writing pickle\")\n",
    "\n",
    "#pickle 読み込み \n",
    "def read_pickle(pickle_path):\n",
    "    with open(pickle_path, mode='rb') as f:\n",
    "        read = pickle.load(f)\n",
    "    return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "resize = 128\n",
    "X = []\n",
    "for path in y[\"file_name\"]:\n",
    "    X.append(np.hstack(get_img_array(basepath + \"train/%s\"%(path), resize)))\n",
    "X = pd.DataFrame(X)\n",
    "X.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_prediction_files  = get_jpg_name(basepath+\"test/\")    #予測するやつ\n",
    "\n",
    "X_prediction_data = []\n",
    "for i in range(len(X_prediction_files)):\n",
    "    X_prediction_data.append(np.hstack(get_img_array(basepath + \"test/test_%s.jpg\"%(i), resize)))\n",
    "X_prediction_data = pd.DataFrame(X_prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X, y, test_size=0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_for_keras(X):\n",
    "    X_n = X/255\n",
    "    X_n.astype(\"float32\")\n",
    "    X_n = X_n.values.reshape(X.shape[0], 3, 128, 128)    \n",
    "    return X_n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pred = model.predict(X_train_keras)\n",
    "X_test_pred  = model.predict(X_test_keras)\n",
    "train_accuracy = M_accuracy(true=y_train, pred=y_train_pred)\n",
    "test_accuracy  = M_accuracy(true=y_test, pred=y_test_pred)\n",
    "print(\"Train Accuracy: %s\\n Test Accuracy: %s\"%(train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(path, pred_array,  X_prediction_files):\n",
    "    #test_filesの順番がsample_submissionとは異なるため、変更する.\n",
    "    submit_dic = {}\n",
    "    for i,name in enumerate(X_prediction_files):\n",
    "        submit_dic[name] = pred_array[i]\n",
    "\n",
    "    submit_list = [] \n",
    "    for i in range(len(submit_dic)):\n",
    "        submit_list.append([\"test_%s.jpg\"%(i),submit_dic[\"test_%s.jpg\"%(i)]])    \n",
    "\n",
    "    pd.DataFrame(submit_list).to_csv(path, index=None,columns=None)\n",
    "    print(\"Finished Writing Submission file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_prediction_keras = preprocessing_for_keras(X_prediction_data)\n",
    "pred_array = model.predict(X_prediction_keras)\n",
    "\n",
    "make_submission(\"Desktop/~~.csv\", pred_array = pred_array, X_prediction_files = X_prediction_files )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
