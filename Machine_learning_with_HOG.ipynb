{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_jpg_name(path):\n",
    "    import os \n",
    "    img_files = os.listdir(path)\n",
    "    return [jpg for jpg in img_files if \".jpg\" in jpg]\n",
    "\n",
    "basepath = \"../first_retailing/\"\n",
    "X_train_files = get_jpg_name(basepath+\"train/\") #学習用\n",
    "test_files  = get_jpg_name(basepath+\"test/\")    #予測するやつ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(basepath+\"train_master.tsv\",sep=\"\\t\")\n",
    "#y_test = pd.read_csv(basepath+\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1.jpg</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  category_id\n",
       "0  train_0.jpg           21\n",
       "1  train_1.jpg           22\n",
       "2  train_2.jpg           11\n",
       "3  train_3.jpg           18\n",
       "4  train_4.jpg           21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utils\n",
    "#画像のpixelを作成\n",
    "def get_img_array(path,resize):\n",
    "    img_array = Image.open(path).resize([resize,resize]).getdata()\n",
    "    return img_array\n",
    "\n",
    "def get_HOG(img_array):\n",
    "    return np.array( hog( img_array, orientations = 6, pixels_per_cell = (3, 3), cells_per_block = (1, 1) )) \n",
    "\n",
    "#精度\n",
    "def M_accuracy(true, pred):\n",
    "    M_acc = {}\n",
    "    for i in range(24):\n",
    "        y_id = pred[true[\"category_id\"].values==i] == i\n",
    "        M_acc[i]=np.mean(y_id)\n",
    "    return  np.mean([j for j in M_acc.values()])\n",
    "\n",
    "def classifaction_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "X_test = []\n",
    "for path in y_test[\"file_name\"]:\n",
    "    X_test.append(np.hstack(get_img_array(basepath + \"X_test/%s\"%(path), 10)))\n",
    "\"\"\"    \n",
    "\n",
    "X_train = []\n",
    "for path in y_train[\"file_name\"]:\n",
    "    X_train.append(np.hstack(get_img_array(basepath + \"train/%s\"%(path), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for path in test_files:\n",
    "    test.append(np.hstack(get_img_array(basepath + \"test/%s\"%(path), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "#X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train[\"category_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chang/.pyenv/versions/python351/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X_train,y_train,test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Train Accuracy: 1.0\n",
      " Test Accuracy: 0.042743625718\n",
      "\n",
      "LinearSVC\n",
      "Train Accuracy: 0.311785368431\n",
      " Test Accuracy: 0.181863355781\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Train Accuracy: 1.0\n",
      " Test Accuracy: 0.363267232824\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.979500326594\n",
      " Test Accuracy: 0.385260444102\n",
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.108193824414\n",
      " Test Accuracy: 0.103353357486\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Train Accuracy: 0.961659554494\n",
      " Test Accuracy: 0.435015423001\n",
      "\n",
      "KNeighborsClassifier\n",
      "Train Accuracy: 0.435939661146\n",
      " Test Accuracy: 0.28263432596\n",
      "\n",
      "XGBClassifier\n",
      "Train Accuracy: 0.844827475906\n",
      " Test Accuracy: 0.443575926132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try various model in sklearn\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "classifiers = [\n",
    "    SVC(),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier( random_state=0 ),\n",
    "    RandomForestClassifier( random_state=0 ),\n",
    "    AdaBoostClassifier( random_state=0 ),\n",
    "    GradientBoostingClassifier( random_state=0 ),\n",
    "    KNeighborsClassifier(),\n",
    "    xgb.XGBClassifier()    \n",
    "                ]\n",
    "\n",
    "def multi_clf(classifiers,X_train,y_train,X_test, y_test):\n",
    "    \n",
    "    # Logging for Visual Comparison\n",
    "    log_cols=[\"Classifier\", \"CV_Accuracy\"]\n",
    "    log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        print(name)\n",
    "        try: \n",
    "            clf.fit(X_train,y_train[\"category_id\"]) #using 10-fold \n",
    "            y_train_pred = clf.predict(X_train)\n",
    "            y_test_pred = clf.predict(X_test)\n",
    "            train_accuracy = M_accuracy(true=y_train, pred=y_train_pred)\n",
    "            test_accuracy  = M_accuracy(true=y_test, pred=y_test_pred)\n",
    "            print(\"Train Accuracy: %s\\n Test Accuracy: %s\"%(train_accuracy, test_accuracy))\n",
    "            print(\"\")\n",
    "            log_entry = pd.DataFrame([[name, test_accuracy]], columns=log_cols)\n",
    "            log = log.append(log_entry)\n",
    "            \n",
    "        except: \n",
    "            print(\"Could't Eval\")\n",
    "            pass\n",
    "    \n",
    "    return log\n",
    "\n",
    "log_all = multi_clf(classifiers,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xgboostを使用\n",
    "xgbc = xgb.XGBClassifier(seed=0)\n",
    "xgbc.fit(X_train,y_train[\"category_id\"])\n",
    "test_pred = xgbc.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_filesの順番がsample_submissionとは異なるため、変更する.\n",
    "submit_dic = {}\n",
    "for i,name in enumerate(test_files):\n",
    "    submit_dic[name] = test_pred[i]\n",
    "\n",
    "submit_list = [] \n",
    "for i in range(len(submit_dic)):\n",
    "    submit_list.append([\"test_%s.jpg\"%(i),submit_dic[\"test_%s.jpg\"%(i)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(submit_list).to_csv(\"submit2.csv\",index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameter:  {'max_depth': 7, 'n_estimators': 259, 'subsample': 0.65302468762759736}\n"
     ]
    }
   ],
   "source": [
    "#RS\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "import scipy as sp\n",
    "\n",
    "param_distributions={'max_depth': sp.stats.randint(1,11),\n",
    "                     'n_estimators':sp.stats.randint(50,400),\n",
    "                     'subsample': sp.stats.uniform(0.5,0.5)\n",
    "}    \n",
    "\n",
    "xgb_model = xgb.XGBClassifier(seed=0)\n",
    "xgb_rs = RandomizedSearchCV(xgb_model,\n",
    "                            param_distributions,\n",
    "                            cv=3,              #CV数\n",
    "                            n_iter=10,          #何回試すか\n",
    "                            scoring=\"accuracy\", #\n",
    "                            n_jobs=1,           #使用コア数\n",
    "                            verbose=0,          #表示形式\n",
    "                            random_state=1)\n",
    "\n",
    "xgb_rs.fit(X_train,y_train[\"category_id\"])\n",
    "print(\"Best Model Parameter: \",xgb_rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      " Test Accuracy: 0.491152936508\n"
     ]
    }
   ],
   "source": [
    "y_train_pred =  xgb_rs.predict(X_train)\n",
    "y_test_pred =  xgb_rs.predict(X_test)\n",
    "\n",
    "train_accuracy = M_accuracy(true=y_train, pred=y_train_pred)\n",
    "test_accuracy  = M_accuracy(true=y_test, pred=y_test_pred)\n",
    "print(\"Train Accuracy: %s\\n Test Accuracy: %s\"%(train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = xgb_rs.predict(test)\n",
    "\n",
    "#test_filesの順番がsample_submissionとは異なるため、変更する.\n",
    "submit_dic = {}\n",
    "for i,name in enumerate(test_files):\n",
    "    submit_dic[name] = test_pred[i]\n",
    "\n",
    "submit_list = [] \n",
    "for i in range(len(submit_dic)):\n",
    "    submit_list.append([\"test_%s.jpg\"%(i),submit_dic[\"test_%s.jpg\"%(i)]])\n",
    "\n",
    "pd.DataFrame(submit_list).to_csv(\"submit2.csv\",index=None,columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBSアルゴリズム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SBS(sequential backward selection)algorithm\n",
    "#全特徴量の中から抜いても一番影響の少ない(精度が下がらない)特徴量を1つずつ抜き続ける\n",
    "\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,random_state=1):\n",
    "        self.scoring = scoring             #特徴量を評価\n",
    "        self.estimator = clone(estimator)  #推定器\n",
    "        self.k_features = k_features       #選択する特徴量の個数\n",
    "        self.random_state = random_state   #乱数種を固定するrandom_state\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        dim = X_train.shape[1] #列数\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        pg = ProgressBar( maxval=dim )\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            #長さrのタプル列, 繰り返しを許さない組合せ\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            self.scores_.append(scores[best])\n",
    "            pg.update(i+1)            \n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, indices):\n",
    "        acc= cross_val_score(self.estimator, X_train.iloc[:, indices], y_train, \n",
    "                                scoring=\"accuracy\",cv = 3) \n",
    "        score = np.mean(acc)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"starting evaluation of SBS\")\n",
    "xgbC = xgb.XGBClassifier()\n",
    "sbs = SBS(xgbC,k_features=1)\n",
    "\n",
    "print(\"Fit SBS\")\n",
    "sbs.fit(pd.DataFrame(X_train),y_train[\"category_id\"])\n",
    "\n",
    "print(\"Plot\")\n",
    "#特徴量の数の推移\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG特徴量を用いたモデリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train_files\n",
    "X_train_hog = []\n",
    "for path in y_train[\"file_name\"]:\n",
    "    resize = 10\n",
    "    hog_feature = get_HOG(get_img_array(basepath+\"train/\"+path,resize))\n",
    "    if hog:\n",
    "        X_train_hog.append(hog_feature)\n",
    "    else:\n",
    "        X_train_hog.append(np.zeros(len(X_train_hog[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_files\n",
    "test_hog = []\n",
    "for path in test_files:\n",
    "    resize = 10\n",
    "    hog_feature = get_HOG(get_img_array(basepath+\"test/\"+path,resize))\n",
    "    if hog:\n",
    "        test_hog.append(hog_feature)\n",
    "    else:\n",
    "        test_hog.append(np.zeros(len(X_train_hog[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chang/.pyenv/versions/python351/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_hog = pd.DataFrame(X_train_hog)\n",
    "test = pd.DataFrame(test_hog)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X_train_hog, y_train,test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6199, 198)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Train Accuracy: 0.120342608212\n",
      " Test Accuracy: 0.116508049307\n",
      "\n",
      "LinearSVC\n",
      "Train Accuracy: 0.372871921929\n",
      " Test Accuracy: 0.194406152199\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Train Accuracy: 1.0\n",
      " Test Accuracy: 0.201611882305\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.985723624197\n",
      " Test Accuracy: 0.217229293693\n",
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.089810200327\n",
      " Test Accuracy: 0.0785694568035\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Train Accuracy: 0.894200142111\n",
      " Test Accuracy: 0.268846121836\n",
      "\n",
      "KNeighborsClassifier\n",
      "Train Accuracy: 0.367173779823\n",
      " Test Accuracy: 0.183691476809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try various model in sklearn\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "classifiers = [\n",
    "    SVC(),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier( random_state=0 ),\n",
    "    RandomForestClassifier( random_state=0 ),\n",
    "    AdaBoostClassifier( random_state=0 ),\n",
    "    GradientBoostingClassifier( random_state=0 ),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "def multi_clf(classifiers,X_train,y_train,X_test, y_test):\n",
    "    \n",
    "    # Logging for Visual Comparison\n",
    "    log_cols=[\"Classifier\", \"CV_Accuracy\"]\n",
    "    log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        print(name)\n",
    "        try: \n",
    "            clf.fit(X_train,y_train[\"category_id\"]) #using 10-fold \n",
    "            y_train_pred = clf.predict(X_train)\n",
    "            y_test_pred = clf.predict(X_test)\n",
    "            train_accuracy = M_accuracy(true=y_train, pred=y_train_pred)\n",
    "            test_accuracy  = M_accuracy(true=y_test, pred=y_test_pred)\n",
    "            print(\"Train Accuracy: %s\\n Test Accuracy: %s\"%(train_accuracy, test_accuracy))\n",
    "            print(\"\")\n",
    "            log_entry = pd.DataFrame([[name, test_accuracy]], columns=log_cols)\n",
    "            log = log.append(log_entry)\n",
    "            \n",
    "        except: \n",
    "            print(\"Could't Eval\")\n",
    "            pass\n",
    "    \n",
    "    return log\n",
    "\n",
    "log_all = multi_clf(classifiers,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
